{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67747b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing the XGBoost classifier we shall use later.\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Introducing Synthetic Minority Over-sampling Technique (SMOTE), which handles imbalanced binary datasets in which 0 or 1 dominates. \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    make_scorer, balanced_accuracy_score\n",
    ")\n",
    "\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b36f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the names for entibiotics, and reading their files.\n",
    "antibiotics = ['Gentamicin', 'Trimethoprim_Sulfamethoxazole', 'Ciprofloxacin',\n",
    "                'Ampicillin', 'Cefazolin','Nitrofurantoin','Piperacillin_Tazobactam',\n",
    "                'Levofloxacin', 'Ceftriaxone']\n",
    "\n",
    "# Fix a random state for reproducability.\n",
    "n_randstat = 312 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac6123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 1 â€” training inner search for Gentamicin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.5686100390512191, 'xgb__n_estimators': 161}\n",
      "Best inner score: 0.11763451290565285\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 2 â€” training inner search for Gentamicin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.7579423061432639, 'xgb__n_estimators': 181}\n",
      "Best inner score: 0.12409063938790442\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 3 â€” training inner search for Gentamicin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.7579423061432639, 'xgb__n_estimators': 181}\n",
      "Best inner score: 0.12638988044117117\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 4 â€” training inner search for Gentamicin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.5686100390512191, 'xgb__n_estimators': 161}\n",
      "Best inner score: 0.1343294635893832\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 5 â€” training inner search for Gentamicin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.6996701670563736, 'xgb__n_estimators': 88}\n",
      "Best inner score: 0.113740400797383\n",
      "\n",
      "\n",
      "===== Nested CV Summary for Gentamicin=====\n",
      "   fold    recall        f1       FNR\n",
      "0     1  0.326531  0.768363  0.673469\n",
      "1     2  0.408163  0.757868  0.591837\n",
      "2     3  0.272727  0.733065  0.727273\n",
      "3     4  0.252525  0.711021  0.747475\n",
      "4     5  0.282828  0.729806  0.717172\n",
      "Mean Accuracy: 0.6625482625482626\n",
      "Mean Recall: 0.3085549371263657\n",
      "Mean F1: 0.7400246095362529\n",
      "Mean false negative rate: 0.6914450628736344\n",
      "Saved results to results_Gentamicin.csv\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 1 â€” training inner search for Trimethoprim_Sulfamethoxazole\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.2050541914059188, 'xgb__n_estimators': 180}\n",
      "Best inner score: 0.30286674913743833\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 2 â€” training inner search for Trimethoprim_Sulfamethoxazole\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.19582605480798962, 'xgb__n_estimators': 106}\n",
      "Best inner score: 0.2911766523524597\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 3 â€” training inner search for Trimethoprim_Sulfamethoxazole\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.3828545147504294, 'xgb__n_estimators': 50}\n",
      "Best inner score: 0.30402167770331984\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 4 â€” training inner search for Trimethoprim_Sulfamethoxazole\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.5686100390512191, 'xgb__n_estimators': 161}\n",
      "Best inner score: 0.2925610174735074\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 5 â€” training inner search for Trimethoprim_Sulfamethoxazole\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.6996701670563736, 'xgb__n_estimators': 88}\n",
      "Best inner score: 0.28176480538785204\n",
      "\n",
      "\n",
      "===== Nested CV Summary for Trimethoprim_Sulfamethoxazole=====\n",
      "   fold    recall        f1       FNR\n",
      "0     1  0.378378  0.562841  0.621622\n",
      "1     2  0.408784  0.607237  0.591216\n",
      "2     3  0.351351  0.561361  0.648649\n",
      "3     4  0.391892  0.584432  0.608108\n",
      "4     5  0.405405  0.623132  0.594595\n",
      "Mean Accuracy: 0.5556756756756757\n",
      "Mean Recall: 0.3871621621621622\n",
      "Mean F1: 0.5878005841265679\n",
      "Mean false negative rate: 0.6128378378378379\n",
      "Saved results to results_Trimethoprim_Sulfamethoxazole.csv\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 1 â€” training inner search for Ciprofloxacin\n",
      "==============================\n",
      "Best inner parameters: {'xgb__learning_rate': 0.19582605480798962, 'xgb__n_estimators': 106}\n",
      "Best inner score: 0.24148180199538047\n",
      "\n",
      "==============================\n",
      "ðŸ”¹ Outer Fold 2 â€” training inner search for Ciprofloxacin\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for anti in antibiotics:\n",
    "\n",
    "    all_results = []      #Creating dataframe to store model measurement results later.\n",
    "\n",
    "\n",
    "    # Load and prepare data\n",
    "    train_df = pd.read_csv(\n",
    "        f\"Final_dataframe-20251015T154934Z-1-001\\\\Final_dataframe\\\\{anti}_train_data.csv\"\n",
    "    )\n",
    "\n",
    "    X = train_df.drop(columns=[anti, 'Year', 'anon_id'])\n",
    "    y = train_df[anti] - 1  # Convert {1,2} to {0,1}\n",
    "\n",
    "\n",
    "    # Define base pipeline  \n",
    "    # Note: for XGBoost, we do not need employ Standard Scaler.\n",
    "    base_pipeline = Pipeline([\n",
    "         ('smote', SMOTE(              # Introducing SMOTE to handle imbalanced data.\n",
    "        sampling_strategy=1.0,     \n",
    "        random_state=n_randstat,             \n",
    "        )),\n",
    "        ('xgb', XGBClassifier(         # Introducing XGBoost classifier.\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            random_state=n_randstat\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # Hyperparameter space for random parameter search.\n",
    "    param_distributions = {\n",
    "        'xgb__n_estimators': list(range(50,200,1)),\n",
    "        'xgb__learning_rate': uniform(0.01,0.9)       \n",
    "    }\n",
    "\n",
    "\n",
    "    # Scoring setup (all using FÎ²)\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score, zero_division=0),\n",
    "        'recall': make_scorer(recall_score, zero_division=0),         # Maximizing recall is equivalent to minimizing fall negative rate, as they always sum up to be 1.\n",
    "        'precision': make_scorer(precision_score, zero_division=0),\n",
    "        'f1': make_scorer(f1_score, average = 'weighted', zero_division=0),      # Using weighted F1 score for model evaluation.\n",
    "        'balanced_accuracy': make_scorer(balanced_accuracy_score, zero_division = 0),\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    # Nested CV setup\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=n_randstat)    # Outer 5-fold loop for cross-validation.\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=n_randstat)    # Inner 3-fold loop for hyper-parameter tuning.\n",
    "\n",
    "    outer_results = []\n",
    "    outer_fold = 1\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X, y):                         # Outer 5-fold loop for cross-validation.\n",
    "        print(f\"\\n==============================\")\n",
    "        print(f\"ðŸ”¹ Outer Fold {outer_fold} â€” training inner search for {anti}\")\n",
    "        print(f\"==============================\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # ---- Inner hyperparameter tuning ----\n",
    "        search = RandomizedSearchCV(                      # Defining the randomized searching module.\n",
    "            estimator=base_pipeline,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter= 10,     # Iteration time for randomized searching.\n",
    "            scoring= 'f1',  # using weighted f1 for optimization\n",
    "            cv=inner_cv,    # Using a inner 3-fold for hyper-parameter tuning.\n",
    "            random_state=n_randstat\n",
    "        )\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best inner parameters:\", search.best_params_)\n",
    "        print(f\"Best inner score:\", search.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "        # ---- Evaluate on outer fold ----\n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        fnr = 1 - recall          # False negative rate is equal to (1-recall).\n",
    "\n",
    "        outer_results.append({\n",
    "            'fold': outer_fold,\n",
    "            'best_params': search.best_params_,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'FNR': fnr\n",
    "        })\n",
    "\n",
    "        outer_fold += 1    \n",
    "    \n",
    "\n",
    "    # Aggregate final performance\n",
    "    outer_df = pd.DataFrame(outer_results)\n",
    "    print(f\"\\n\\n===== Nested CV Summary for {anti}=====\")\n",
    "    print(outer_df[['fold', 'recall', 'f1', 'FNR']])\n",
    "    print(\"Mean Accuracy:\", outer_df['accuracy'].mean())\n",
    "    print(\"Mean Recall:\", outer_df['recall'].mean())                \n",
    "    print(f\"Mean F1:\", outer_df['f1'].mean())\n",
    "    print(\"Mean false negative rate:\", outer_df['FNR'].mean())\n",
    "\n",
    "    # Save per-antibiotic result CSV\n",
    "    output_path = f\"results_{anti}.csv\"\n",
    "    outer_df.to_csv(output_path, index=False)         \n",
    "    print(f\"Saved results to {output_path}\")\n",
    "\n",
    "    # Add to results list\n",
    "    all_results.append(outer_df)\n",
    "\n",
    "\n",
    "# Merge all antibiotics' results together and save into .csv.\n",
    "final_df = pd.concat(all_results, ignore_index=True)\n",
    "final_df.to_csv(\"all_antibiotics_results.csv\", index=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
